{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the first part of TensorFlow tutorial\n",
    "The idea is to show the basic computation patterns, \n",
    "and write simple models for hand-written digit classification on MNIST dataset\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## Section 1: TF basics\n",
    "#  1.1 Graphs and sessions\n",
    "A = tf.Variable(2)\n",
    "# del\n",
    "B = tf.Variable(3)\n",
    "C = A+B\n",
    "print (C)\n",
    "## TODO: Write a simple calculation C=A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "## Build a session to execute the computation\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print (sess.run(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "## close your previous session\n",
    "## and clear its information\n",
    "tf.reset_default_graph()\n",
    "sess.close()\n",
    "\n",
    "## Below is how you use an interactive session\n",
    "## Can you see the difference?\n",
    "sess = tf.InteractiveSession()\n",
    "A = tf.Variable(2)\n",
    "# del\n",
    "B = tf.Variable(3)\n",
    "C = A+B\n",
    "tf.global_variables_initializer().run()\n",
    "print (C.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## close your previous session\n",
    "## and clear its information\n",
    "tf.reset_default_graph()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-2f07f007f620>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tieqiao1024/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "## Section 1: Building a model with TF\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "file = \"./MNIST\"\n",
    "mnist = input_data.read_data_sets(file, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# Please read and run this example, \n",
    "# And see a minimal instance of TensorFlow\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "for i in range(300):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8531\n"
     ]
    }
   ],
   "source": [
    "# Use the testing set to see the model accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_:mnist.test.labels}))\n",
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-e38c920a243a>:50: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2\n",
    "# Now try by yourself to build a 2-conv + 1FC layer\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# DEL from here\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "# ends del here\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 10, training accuracy 0.17\n",
      "step 20, training accuracy 0.37\n",
      "step 30, training accuracy 0.58\n",
      "step 40, training accuracy 0.7\n",
      "step 50, training accuracy 0.79\n",
      "step 60, training accuracy 0.77\n",
      "step 70, training accuracy 0.84\n",
      "step 80, training accuracy 0.85\n",
      "step 90, training accuracy 0.85\n",
      "step 100, training accuracy 0.87\n",
      "step 110, training accuracy 0.9\n",
      "step 120, training accuracy 0.9\n",
      "step 130, training accuracy 0.91\n",
      "step 140, training accuracy 0.89\n",
      "step 150, training accuracy 0.93\n",
      "step 160, training accuracy 0.91\n",
      "step 170, training accuracy 0.88\n",
      "step 180, training accuracy 0.94\n",
      "step 190, training accuracy 0.88\n",
      "step 200, training accuracy 0.94\n",
      "step 210, training accuracy 0.92\n",
      "step 220, training accuracy 0.93\n",
      "step 230, training accuracy 0.91\n",
      "step 240, training accuracy 0.99\n",
      "step 250, training accuracy 0.94\n",
      "step 260, training accuracy 0.95\n",
      "step 270, training accuracy 0.91\n",
      "step 280, training accuracy 0.97\n",
      "step 290, training accuracy 0.93\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(300):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i%10 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    #print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    #    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9395\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2.3\n",
    "# Some \"layer\" API calls brought by TF\n",
    "# This is not finished\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "conv1=tf.layers.conv2d(inputs=x_image, kernel_size=[5,5], filters=32)\n",
    "pool1=tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=1)\n",
    "# del here\n",
    "conv2=tf.layers.conv2d(inputs=conv1, kernel_size=[5,5], filters=64)\n",
    "pool2=tf.layers.max_pooling2d(inputs=conv2, pool_size=2, strides=1)\n",
    "h_pool2_flat = tf.layers.flatten(pool2)\n",
    "h_fc1_drop = tf.nn.dropout(h_pool2_flat, keep_prob)\n",
    "h_fc2=tf.layers.dense(h_fc1_drop,1024,activation=\"relu\")\n",
    "y_conv=tf.layers.dense(h_pool2_flat,10)\n",
    "# ends del here\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.07\n",
      "step 10, training accuracy 0.71\n",
      "step 20, training accuracy 0.75\n",
      "step 30, training accuracy 0.81\n",
      "step 40, training accuracy 0.83\n",
      "step 50, training accuracy 0.8\n",
      "step 60, training accuracy 0.83\n",
      "step 70, training accuracy 0.83\n",
      "step 80, training accuracy 0.85\n",
      "step 90, training accuracy 0.85\n",
      "step 100, training accuracy 0.92\n",
      "step 110, training accuracy 0.91\n",
      "step 120, training accuracy 0.96\n",
      "step 130, training accuracy 0.9\n",
      "step 140, training accuracy 0.9\n",
      "step 150, training accuracy 0.92\n",
      "step 160, training accuracy 0.9\n",
      "step 170, training accuracy 0.92\n",
      "step 180, training accuracy 0.91\n",
      "step 190, training accuracy 0.93\n",
      "step 200, training accuracy 0.91\n",
      "step 210, training accuracy 0.95\n",
      "step 220, training accuracy 0.93\n",
      "step 230, training accuracy 0.95\n",
      "step 240, training accuracy 0.9\n",
      "step 250, training accuracy 0.9\n",
      "step 260, training accuracy 0.9\n",
      "step 270, training accuracy 0.9\n",
      "step 280, training accuracy 0.88\n",
      "step 290, training accuracy 0.92\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(300):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i%10 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    #print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    #    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9285\n"
     ]
    }
   ],
   "source": [
    "# Again, test the accuracy of this model\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
